{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyOT3r0EJrPx9kVV8w95Qdb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahoangnhatphi/AIN501C/blob/main/2_Number_series_with_machine_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number sequence"
      ],
      "metadata": {
        "id": "AhzOU75JTC-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# Generate sequence\n",
        "fib_sequence = [1, 1]\n",
        "for i in range(2, 100):\n",
        "    next_number = fib_sequence[-1] + 2 * fib_sequence[-2]\n",
        "    fib_sequence.append(next_number)\n",
        "for i, value in enumerate(fib_sequence, start=1):\n",
        "    print(f\"x{i-1} = {value}\")\n",
        "\n",
        "print('Predicted number: ', fib_sequence[-1] + 2 * fib_sequence[-2])"
      ],
      "metadata": {
        "id": "xXlsKzQTTb9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5b093c-e1ac-4cc4-e451-f2b2daff589b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x0 = 1\n",
            "x1 = 1\n",
            "x2 = 3\n",
            "x3 = 5\n",
            "x4 = 11\n",
            "x5 = 21\n",
            "x6 = 43\n",
            "x7 = 85\n",
            "x8 = 171\n",
            "x9 = 341\n",
            "x10 = 683\n",
            "x11 = 1365\n",
            "x12 = 2731\n",
            "x13 = 5461\n",
            "x14 = 10923\n",
            "x15 = 21845\n",
            "x16 = 43691\n",
            "x17 = 87381\n",
            "x18 = 174763\n",
            "x19 = 349525\n",
            "x20 = 699051\n",
            "x21 = 1398101\n",
            "x22 = 2796203\n",
            "x23 = 5592405\n",
            "x24 = 11184811\n",
            "x25 = 22369621\n",
            "x26 = 44739243\n",
            "x27 = 89478485\n",
            "x28 = 178956971\n",
            "x29 = 357913941\n",
            "x30 = 715827883\n",
            "x31 = 1431655765\n",
            "x32 = 2863311531\n",
            "x33 = 5726623061\n",
            "x34 = 11453246123\n",
            "x35 = 22906492245\n",
            "x36 = 45812984491\n",
            "x37 = 91625968981\n",
            "x38 = 183251937963\n",
            "x39 = 366503875925\n",
            "x40 = 733007751851\n",
            "x41 = 1466015503701\n",
            "x42 = 2932031007403\n",
            "x43 = 5864062014805\n",
            "x44 = 11728124029611\n",
            "x45 = 23456248059221\n",
            "x46 = 46912496118443\n",
            "x47 = 93824992236885\n",
            "x48 = 187649984473771\n",
            "x49 = 375299968947541\n",
            "x50 = 750599937895083\n",
            "x51 = 1501199875790165\n",
            "x52 = 3002399751580331\n",
            "x53 = 6004799503160661\n",
            "x54 = 12009599006321323\n",
            "x55 = 24019198012642645\n",
            "x56 = 48038396025285291\n",
            "x57 = 96076792050570581\n",
            "x58 = 192153584101141163\n",
            "x59 = 384307168202282325\n",
            "x60 = 768614336404564651\n",
            "x61 = 1537228672809129301\n",
            "x62 = 3074457345618258603\n",
            "x63 = 6148914691236517205\n",
            "x64 = 12297829382473034411\n",
            "x65 = 24595658764946068821\n",
            "x66 = 49191317529892137643\n",
            "x67 = 98382635059784275285\n",
            "x68 = 196765270119568550571\n",
            "x69 = 393530540239137101141\n",
            "x70 = 787061080478274202283\n",
            "x71 = 1574122160956548404565\n",
            "x72 = 3148244321913096809131\n",
            "x73 = 6296488643826193618261\n",
            "x74 = 12592977287652387236523\n",
            "x75 = 25185954575304774473045\n",
            "x76 = 50371909150609548946091\n",
            "x77 = 100743818301219097892181\n",
            "x78 = 201487636602438195784363\n",
            "x79 = 402975273204876391568725\n",
            "x80 = 805950546409752783137451\n",
            "x81 = 1611901092819505566274901\n",
            "x82 = 3223802185639011132549803\n",
            "x83 = 6447604371278022265099605\n",
            "x84 = 12895208742556044530199211\n",
            "x85 = 25790417485112089060398421\n",
            "x86 = 51580834970224178120796843\n",
            "x87 = 103161669940448356241593685\n",
            "x88 = 206323339880896712483187371\n",
            "x89 = 412646679761793424966374741\n",
            "x90 = 825293359523586849932749483\n",
            "x91 = 1650586719047173699865498965\n",
            "x92 = 3301173438094347399730997931\n",
            "x93 = 6602346876188694799461995861\n",
            "x94 = 13204693752377389598923991723\n",
            "x95 = 26409387504754779197847983445\n",
            "x96 = 52818775009509558395695966891\n",
            "x97 = 105637550019019116791391933781\n",
            "x98 = 211275100038038233582783867563\n",
            "x99 = 422550200076076467165567735125\n",
            "Predicted number:  845100400152152934331135470251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try ML model from simple to complex to predict number"
      ],
      "metadata": {
        "id": "LnfjVThxE2q1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "BRzbzVwJhtz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate sequence\n",
        "def generate_sequence(n):\n",
        "    seq = [1, 1]\n",
        "    for i in range(2, n):\n",
        "        seq.append(seq[i - 1] + 2 * seq[i - 2])\n",
        "    return seq\n",
        "\n",
        "n = 100\n",
        "seq = generate_sequence(n)\n",
        "\n",
        "# Prepares the data for linear regression\n",
        "X = np.array(range(1, n+1)).reshape(-1, 1)\n",
        "y = np.array(seq).reshape(-1, 1)\n",
        "\n",
        "# Creates and trains a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predicts the value for the 101st number\n",
        "predicted_number_value = model.predict(np.array([[101]]))\n",
        "\n",
        "print(\"Predicted number 101: \", predicted_number_value[0][0])"
      ],
      "metadata": {
        "id": "NCAvJ72shytV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a27d86b-2fba-4717-ca10-f93561f1775a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted number 101:  3.3291833945387846e+28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM (Long Short-Term Memory)"
      ],
      "metadata": {
        "id": "4-hde0iIXzvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate sequence\n",
        "def generate_sequence(n):\n",
        "    seq = [1, 1]\n",
        "    for i in range(2, n):\n",
        "        seq.append(seq[i - 1] + 2 * seq[i - 2])\n",
        "    return seq\n",
        "\n",
        "n = 101\n",
        "sequence = generate_sequence(n)\n",
        "\n",
        "# Transform sequence\n",
        "X = np.array(sequence[:-1]).reshape(-1, 1)\n",
        "y = np.array(sequence[1:]).reshape(-1, 1)\n",
        "\n",
        "#  Use MinMaxScaler to normalize the input and target data, scaling them to a range between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# The data is reshaped to match the expected input shape for an LSTM model, which is (batch_size, timesteps, features). In your case, you have a single feature, so the shape becomes (batch_size, 1, 1)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "y = y.reshape(y.shape[0], 1, y.shape[1])\n",
        "\n",
        "# Model has one LSTM layer with 50 units and a ReLU activation function. The output layer is a Dense layer with a single unit\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, activation='relu', input_shape=(1, 1)))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Compile Adam optimizer and mean squared error (MSE) loss function\n",
        "model.fit(X, y, epochs=100, batch_size=8, verbose=1)\n",
        "\n",
        "# Make prediction for number 101th\n",
        "predict_number = np.array([sequence[100]]).reshape(-1, 1)\n",
        "predict_number = scaler.transform(predict_number)\n",
        "predict_number = predict_number.reshape(1, 1, 1)\n",
        "predict_number_result = model.predict(predict_number)\n",
        "predict_number_result = scaler.inverse_transform(predict_number_result)\n",
        "\n",
        "print(\"Predicted number 101:\", predict_number_result)"
      ],
      "metadata": {
        "id": "qC6eqx6vT6G2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97c3f9e-99e0-4f70-c5d7-1a5d10ef2c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 7ms/step - loss: 0.0135\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0129\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0125\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0123\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0122\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0119\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0118\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0116\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0115\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0113\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0111\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0109\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0108\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0106\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0105\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0103\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0101\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0099\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0097\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0096\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0093\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0090\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0088\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0086\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0084\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0081\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0079\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0075\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0070\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0067\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0065\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0062\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0060\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0057\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0055\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0052\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0049\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0047\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0044\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0039\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0028\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0024\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0018\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0015\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 0.0010\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 9.0764e-04\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 8.2893e-04\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 7.3541e-04\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 6.3223e-04\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 5.6080e-04\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 4.9558e-04\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 4.3852e-04\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 4.0992e-04\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 3.3567e-04\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.8534e-04\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.4788e-04\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 2.5023e-04\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 1.8828e-04\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.5864e-04\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 1.4667e-04\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 12ms/step - loss: 1.2169e-04\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 1.0861e-04\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 9.7492e-05\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.6214e-05\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.8169e-05\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.0791e-05\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.6147e-05\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.1443e-05\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.6938e-05\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5.3968e-05\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.2167e-05\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 5.0060e-05\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5.0291e-05\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.6724e-05\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.5252e-05\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.4508e-05\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.3943e-05\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.3202e-05\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.3191e-05\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.2749e-05\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.2703e-05\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.2401e-05\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.2645e-05\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.2198e-05\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.1273e-05\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.1603e-05\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.1070e-05\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.1967e-05\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.0921e-05\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "Predicted number 101: [[8.6539716e+29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neutral network"
      ],
      "metadata": {
        "id": "TIVe6Vu8X17L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate sequence\n",
        "def generate_sequence(n):\n",
        "    seq = [1, 1]\n",
        "    for i in range(2, n):\n",
        "        seq.append(seq[i - 1] + 2 * seq[i - 2])\n",
        "    return seq\n",
        "\n",
        "n = 101\n",
        "sequence = generate_sequence(n)\n",
        "\n",
        "# Transform Sequence\n",
        "X = np.array(sequence[:-1]).reshape(-1, 1)\n",
        "y = np.array(sequence[1:]).reshape(-1, 1)\n",
        "\n",
        "#  Use MinMaxScaler to normalize the input and target data, scaling them to a range between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# The data is reshaped to match the expected input shape for an LSTM model, which is (batch_size, timesteps, features). In your case, you have a single feature, so the shape becomes (batch_size, 1, 1)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "y = y.reshape(y.shape[0], 1, y.shape[1])\n",
        "\n",
        "# This neural network model with two hidden layers, ReLU activation functions, and mean squared error loss\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim=1))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Compile Adam optimizer and mean squared error (MSE) loss function\n",
        "model.fit(X, y, epochs=100, batch_size=8, verbose=1)\n",
        "\n",
        "# Make prediction for number 101th\n",
        "predict_number = np.array([sequence[100]]).reshape(-1, 1)\n",
        "predict_number = scaler.transform(predict_number)\n",
        "predict_number = predict_number.reshape(1, 1, 1)\n",
        "predict_number_result = model.predict(predict_number)\n",
        "predict_number_result = scaler.inverse_transform(predict_number_result)\n",
        "\n",
        "print(\"Predicted number 101:\", predict_number_result)"
      ],
      "metadata": {
        "id": "9xCqRZ-aYHAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d4862a-a868-4a55-e3b4-9959840e11e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 3s 6ms/step - loss: 0.0178\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0148\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0111\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0092\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0070\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0054\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 0.0025\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 0.0015\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 9.4647e-04\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.1558e-04\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.3256e-04\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.3778e-04\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.3141e-04\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.4507e-05\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 5.8400e-05\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 2.2327e-05\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 1.1700e-05\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.2406e-06\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5.0258e-06\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 3.8551e-06\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 10ms/step - loss: 3.1877e-06\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 9ms/step - loss: 2.5574e-06\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.5420e-06\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.2407e-06\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.2429e-06\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2.3076e-06\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.8128e-06\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2.2668e-06\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.9578e-06\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.6287e-06\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.5640e-06\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.6656e-06\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.7739e-06\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.5422e-06\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.3577e-06\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.3369e-06\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.5048e-06\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.3393e-06\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.4783e-06\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.3191e-06\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2.2443e-06\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.8414e-06\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.5072e-06\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.0290e-06\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.1733e-06\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.1397e-06\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.0673e-07\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 9.1558e-07\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.1882e-06\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.0151e-06\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 8.3786e-07\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.5064e-07\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 8.7439e-07\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.3127e-07\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.2571e-07\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.5939e-07\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.1939e-07\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.3962e-06\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.1313e-06\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9100e-07\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0652e-07\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.2129e-07\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0888e-07\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0105e-07\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.5429e-07\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7613e-07\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6709e-07\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.1693e-07\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 2.7579e-07\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2.4945e-07\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.0463e-07\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.6103e-07\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7904e-07\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1961e-07\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.5856e-07\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 3.7317e-07\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.7893e-07\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 2.5664e-07\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.1322e-07\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.1852e-07\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2.6735e-07\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.8389e-07\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.7430e-07\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.7761e-07\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.5547e-07\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.2435e-07\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.0562e-07\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 1.1704e-07\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.1160e-07\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.0906e-07\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.6176e-07\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.7583e-07\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.1035e-07\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1.0878e-07\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.4704e-08\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.4408e-08\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.3208e-08\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.7020e-08\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "Predicted number 101: [[8.45315e+29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "1jAuX6MjjXCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number 101th: 8.45e+29\n",
        "\n",
        "| Model                  | Result      |\n",
        "| -----------            | ----------- |\n",
        "| Linear Regression      | 3.32e+28    |\n",
        "| LSTM                   | 8.65e+29    |\n",
        "| Neural network         | 8.45e+29    |\n",
        "\n",
        "- The sequence exhibits rapid growth, which can potentially lead to scalability challenges when employing certain models.\n",
        "\n",
        "- While Linear Regression aims to predict the next number based on the current one, it may not be the optimal choice in this scenario due to the non-linear nature of the pattern.\n",
        "\n",
        "- To enhance the model's accuracy, more complex machine learning approaches such as Neural Networks, LSTM can be employed. In this case, we explore prediction using LSTM and Neural Networks.\n",
        "\n",
        "- It's evident that the model's performance progressively improves in the order of Neural Network > LSTM > Linear Regression, with the Neural Network providing the closest approximation\n"
      ],
      "metadata": {
        "id": "yoSFAee6jgVs"
      }
    }
  ]
}